--- 
title: "Immcantation - enchantR"
subtitle: "Define Clones"
author: ""
date: "Updated: `r date()`"
knit: "bookdown::render_book"
site: bookdown::bookdown_site
documentclass: book
bibliography: "references.bib"
biblio-style: apalike
link-citations: yes
description: "enchantr define clones"
output: enchantr::immcantation
params:
   input: 
      label: "`input`: Path to repertoires file"
      input: file
      value: "input.tsv"
   imgt_db:
      label: "`imgt_db`: Path to IMGT reference  database."
      input: file
      value: !r NULL
   cloneby:
      label: "`cloneby`"
      input: text
      value: "sample_id"    
   singlecell:
      label: "`singlecell`"
      input: text
      value: "single_cell"          
   threshold:
      label: "`threshold`"
      input: numeric
      value: 1
   outputby:
      label: "`outputby` name of the column in `input` that contains sample identifiers that will be used to split the output db."      
      input: text
      value: "id"
   model:
      label: "`model`"
      input: text
      value: "hierarchical" 
   method:
       label: "`method`"
       input: text
       value: "nt"
   linkage:
       label: "`linkage`"
       input: text
       value: "single"
   outname:
      label: "`outname`"
      input: text
      value: "define-clones"
   nproc:
      label: "`nproc`"
      input: numeric
      value: 1      
   log:
      label: "`log`"
      input: text
      value: "command_log"
   outdir:
      label: '`outdir`: Output directory'
      input: text
      value: !r file.path(getwd(),'enchantr')
   date: 
      label: '`date`: Run date'
      input: date
      value: !r format(Sys.time(), "%Y-%m-%d")
   logo:
      label: "`logo`: Path to report logo"
      input: file
      value: !r file.path("assets", "logo.png")
   logolink:
      label: "`logolink`: URL to be added to the logo"
      input: text
      value: "immcantation.org"
   echo: 
      label: '`echo`: Show code in the report.'
      input: checkbox
      value: FALSE
   cache:
      label: '`cache`: Use cached results'
      input: checkbox
      value: FALSE
editor_options: 
  chunk_output_type: console
---


```{r global-options, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(fig.width=7, fig.height=4, fig.path = "figures/",
                      echo=params$echo,cache=params$cache,
                      warning=FALSE, message=FALSE,
                      eval.after="fig.cap",
                      out_dir=params$outdir,
                      eval.opts = c('eval', 'echo', 'fig.height', 'fig.width'))

# Libraries
suppressPackageStartupMessages(library("DT"))
suppressPackageStartupMessages(library("dplyr"))
suppressPackageStartupMessages(library("tidyr"))
suppressPackageStartupMessages(library("airr"))
suppressPackageStartupMessages(library("alakazam"))
suppressPackageStartupMessages(library("shazam"))
suppressPackageStartupMessages(library("scoper"))
suppressPackageStartupMessages(library("dowser"))
suppressPackageStartupMessages(library("enchantr"))

file.copy(params$logo, 
          file.path(params$outdir,"assets", paste0("logo", gsub(".+(\\..+$)","\\1",params$logo))),
          recursive = T, overwrite=T)
```


# Input parameters

```{r input-parameters}
if (!dir.exists(params[['outdir']])) {
   dir.create(params[['outdir']], recursive = T)
}
printParams(params)
# save(params, file=file.path(params$outdir,"params.RData"))
```

# Read repertoires

```{r}
# Read repertoire
db<- bind_rows(lapply(strsplit(params[['input']],",")[[1]], function(x) {
    # Check input file
    if (!file.exists(x)) {
        stop(paste0("File ", basename(x), " doesn't exist."))
    }
    read_rearrangement(x)}
))
input_size <- nrow(db)
heavy_chains <- grepl("[hHBbDc]", db[['locus']]) #IGH, TRB, TRD
```

Number of sequences loaded: `r input_size`. Number of heavy chain sequences loaded: `r heavy_chains`.

## Sequences per locus

```{r inputlocussumary}
input_locus_summary <- db %>%
   group_by(!!!rlang::syms(c("sample_id",params$cloneby)), locus) %>%
   summarize(n=n(), .groups="drop") %>%
   pivot_wider(names_from=locus, values_from=n) %>%
   rowwise() %>%
   mutate(Total = sum(!!!rlang::syms(unique(db[['locus']]))))

total <- data.frame(list("sample_id"="Total", 
                    t(input_locus_summary %>%
   select(!!!rlang::syms(c(unique(db[['locus']]), "Total"))) %>%
   colSums(na.rm = T))))

input_locus_summary <- bind_rows(input_locus_summary, total)

eetable(input_locus_summary,
    caption=paste0("Input data. Number of sequences in each ", 
                   paste("sample", params$cloneby, sep=", "),
                   " and locus."
      )
) 
```

```{r eval="c_call" %in% colnames(db), results='asis'}
cat("## Sequences per c_call\n")
```

```{r input-ccall-sumary, eval="c_call" %in% colnames(db)}
input_c_call_summary <- db %>%
   group_by(!!!rlang::syms(c("sample_id",params$cloneby)), c_call) %>%
   summarize(n=n(), .groups="drop") %>%
       pivot_wider(names_from=c_call, values_from=n)

eetable(input_c_call_summary,
    caption=paste0("Input data. Number of sequences in each ", 
                   paste("sample", params$cloneby, sep=", "),
                   " and c_call"
      )
) 
```

# Clonal assignment

Clonal assignment performed with `scoper::hierarchicalClones`, version `r v <- packageVersion("scoper"); v` within `r paste(params$cloneby, collapse=", ")`.

To know more details about the method, visit the documentation website [https://scoper.readthedocs.io/en/](https://scoper.readthedocs.io/en/`r v`/topics/hierarchicalClones/)

```{r, warning=TRUE}
if (sum(heavy_chains)>0) {
    if (params$model == "hierarchical") {
        if (all(db[[ params$singlecell ]] == T )) {
            cell_id <- 'cell_id'
        } else {
            cell_id <- NULL
            if (all(c(T,F) %in% db[[ params$singlecell ]])) {
                warning("Mix of single and bulk data. Setting cell_id=`NULL`.")
            }
        }
        db <- hierarchicalClones(db, 
                                 params$threshold, 
                                 method=params$method,
                                 linkage=params$linkage, 
                                 normalize="len",
                                 junction="junction", 
                                 v_call="v_call", j_call="j_call", 
                                 clone="clone_id", 
                                 fields=params$cloneby,
                                 cell_id=cell_id, 
                                 locus="locus", 
                                 only_heavy=TRUE, 
                                 split_light=TRUE,
                                 first=FALSE, 
                                 cdr3=FALSE, mod3=FALSE, 
                                 max_n=0, nproc=params$nproc,
                                 verbose=FALSE, log=NULL,
                                 summarize_clones=FALSE) 
    } else {
        stop("Unsuported model requested. Supported models: hierarchical")
    }
} else {
    warning("No heavy chain sequences found.")
    db$clone_id <- NA
}
```

`r nrow(db)` sequences passed the clonal assignment step 
and `r input_size - nrow(db)` were removed. `r sum(is.na(db[['clone_id']]))` sequences
have `clone_id==NA`.


## Create germlines

```{r}
dowser_v <- packageVersion("dowser")
```


Identification of the V(D)J germline sequences from which each of the observed 
sequences is derived is performed with `dowser::createGermlines`, version `r dowser_v`.
These reconstructed germlines will be used in downstream analysis to infer somatic 
mutations and reconstruct lineages. 

`dowser::createGermlines` takes the alignment information 
in the rearrangement file as well as the reference database used by the 
alignment software and generates a germline sequence for each individual observed sequence.
Because clonal relations have already been inferred, the function assigns the 
same germline to all sequences belonging to the same clone. 

Two types of germlines
are created, `germline_alignment` and `germline_alignment_d_mask`. The last one
has the D region masked, meaning that all nucleotides in the N/P and D-segments
are replaced with N's. This is often done because the germline base calls from 
this region are unreliable for B cell receptor alignments.

Documentation for `dowser::createGermlines` is available here: [https://dowser.readthedocs.io/en/latest/topics/createGermlines](https://dowser.readthedocs.io/en/latest/topics/createGermlines/).

```{r}
if ( length(unique(db[['species']])) > 1 ) {
    message("Message: multiple species found.")
} 
pre_germ_size <- nrow(db)
db[['tmp_nrow']] <- 1:nrow(db)
db <- bind_rows(lapply(split(db,db[['species']]),
                 function(db_sp) { 
                     species <- db_sp[['species']][1]
                     references <- dowser::readIMGT(file.path(params[['imgt_db']], species, "vdj"))
                     dowser::createGermlines(
                         db_sp,
                         references,
                         locus = "locus",
                         nproc = params$nproc,
                         seq = "sequence_alignment",
                         v_call = "v_call",
                         d_call = "d_call",
                         j_call = "j_call",
                         amino_acid = FALSE,
                         id = "sequence_id",
                         clone = "clone_id",
                         v_germ_start = "v_germline_start",
                         v_germ_end = "v_germline_end",
                         v_germ_length = "v_germline_length",
                         d_germ_start = "d_germline_start",
                         d_germ_end = "d_germline_end",
                         d_germ_length = "d_germline_length",
                         j_germ_start = "j_germline_start",
                         j_germ_end = "j_germline_end",
                         j_germ_length = "j_germline_length",
                         np1_length = "np1_length",
                         np2_length = "np2_length",
                         na.rm = TRUE,
                         fields = params$cloneby,
                     )
                 })) %>%
    arrange(tmp_nrow) %>%
    select(-tmp_nrow) 
```

`r nrow(db)` sequences passed the germline reconstruction step
and `r pre_germ_size - nrow(db)` failed.

# Summary of clonal assignment

Description of terms:

* `clone_size_count`: Clone size as sequence counts. In a sample (`sample_id`), the number of heavy chain 
sequences with the same `clone_id`.

* `clone_size_freq`: Clone size as percent of the repertoire. `clone_size_count` divided by the number of heavy chain sequences in the sample (`sample_id`).


## Number of clones (heavy chain, incl. singletons)

```{r}
# Add clone_size 
clone_sizes <- countClones(
            db %>% filter(grepl("[hHBbDc]", locus)), # Keep heavy chains only
            groups=unique(c("sample_id", params$cloneby)))

db <- db %>%
   left_join(clone_sizes) %>%
   rename(
      clone_size_count = seq_count,
      clone_size_freq = seq_freq
   ) %>% 
   mutate_at(vars(starts_with("clone_size")), round,2)
```

```{r}
num_clones_table <- db %>%
   filter(grepl("[hHBbDc]", locus)) %>% # Keep heavy chains only
   group_by(sample_id) %>%
   mutate(sample_size=n()) %>%
   group_by(sample_id) %>%
   mutate(
      number_of_clones=length(unique(clone_id)),
   ) %>%
   group_by(!!!rlang::syms(c("sample_id","sample_size", params$cloneby, "number_of_clones"))) %>%
   summarize_at(vars(starts_with("clone_size")), list("min"=min, "median"=median, "max"=max)) %>%
   mutate_at(vars(starts_with("clone_size")), round, 2)

eetable(num_clones_table,
    caption="Summary of the number of clones, and clone size, per sample. Includes singletons (clone_size == 1)."
) 
```

## Expanded clones within `sample_id` (heavy chain, without singletons)

```{r}
num_clones_table_nosingle <- db %>%
   filter(grepl("[hHBbDc]", locus)) %>% # Keep heavy chains only
   filter(clone_size_count>1) %>%
   group_by(sample_id) %>%
   mutate(sample_size=n()) %>%
   group_by(sample_id) %>%
   mutate(
      number_of_clones=length(unique(clone_id)),
   ) %>%
   group_by(!!!rlang::syms(c("sample_id","sample_size", params$cloneby, "number_of_clones"))) %>%
   summarize_at(vars(starts_with("clone_size")), list("min"=min, "median"=median, "max"=max)) %>%
   mutate_at(vars(starts_with("clone_size")), round, 2)

eetable(num_clones_table,
    caption="Summary of the number of clones, and clone size, per sample. Includes singletons (clone_size == 1)."
) 

eetable(num_clones_table_nosingle,
    caption="Summary of the number of clones of size > 1, and their clone sizes, per sample."
) 
```

## Expanded clones within `r paste(params$cloneby,collapse=", ")`

```{r}
any_tissues <- db %>%
   filter(grepl("[hHBbDc]", locus)) %>% # Keep heavy chains only
   group_by(!!!rlang::syms(c("clone_id", params$cloneby))) %>%
   summarize(
             clone_size_group_count=n(),
             num_tissues=length(unique(tissue)),
             tissues=paste(sort(unique(tissue)),collapse=" & "), .groups="drop") %>%
   filter(clone_size_group_count>1) %>%
   group_by(!!!rlang::syms(c("tissues", params$cloneby))) %>%
   summarize(num_clones=length(unique(clone_id)))
    
eetable(any_tissues,
    caption=paste0("Summary of expanded clones in ", paste(params$cloneby, collapse = ", "), " and tissues. Subsetting to clones of size > 1 in the cloning group (not the sample).")
) 
```

## Clones spanning multiple tissues

```{r}
multi_tissue <- db %>%
    filter(grepl("[hHBbDc]", locus)) %>% # Keep heavy chains only
    group_by(!!!rlang::syms(c(params$cloneby, "clone_id"))) %>%
    summarize(num_tissues=length(unique(tissue))) %>%
    filter(num_tissues>1)

multi_tissue <- multi_tissue %>%
   left_join(db %>% filter(grepl("[hHBbDc]", locus)), 
   by=c("clone_id", params$cloneby)) %>%
   select(!!!rlang::syms(unique(c("clone_id", "tissue", "sample_id", "clone_size_count", "clone_size_freq", params$clone_by, "sequence_id")))) %>%
   group_by(!!!rlang::syms(c("clone_id", "clone_size_count", "clone_size_freq","tissue", "sample_id", params$clone_by))) %>%
   summarize(seq_count=n())

eetable(multi_tissue,
    caption="Summary of clones spanning more than one tissue."
) 
```

# Clone size distribution

Most real datasets, will have most clones of size 1 (one sequence). Straight sequence count as a mesure of the size of the clones is not the best measure
to compare clone size between samples. See [Clonal abundance](#clonal_abundance)

```{r clone-size, fig.width=8, fig.height=0.7*length(unique(db[['sample_id']]))}
ggplot(clone_sizes, aes(x=seq_count, color=sample_id, fill=sample_id))+
    geom_bar() + theme_bw() +
    facet_wrap(~sample_id, scales = "free_y", ncol=3) +
    xlab("Clone size (Number of sequences per clone)")
```

## Subset to clone size > 1

```{r clone-size-atleast2, fig.width=8}
ggplot(clone_sizes %>% filter(seq_count>1), aes(x=seq_count, color=sample_id, fill=sample_id))+
    geom_bar() + theme_bw() +
    facet_wrap(~sample_id, scales = "free_y", ncol=3) +
    xlab("Clone size (Sequences per clone)")
```


# Clonal abundance {#clonal_abundance}

Clonal abundance is the size of each clone 
(as a fraction of the entire repertoire). `estimateAbundance` estimates the clonal
abundance distribution along with confidence intervals on these clone sizes using bootstrapping. The y-axis shows the clone abundance (i.e., the size as a percent of the repertoire) and the x-axis is a rank of each clone, where the rank is sorted by size from larger (rank 1, left) to smaller (right). The shaded areas are confidence intervals.

```{r abundancebysample}
# calculate the rank-abundance curve
a <- estimateAbundance(db %>% filter(grepl("[hHBbDc]", locus)),
                       group = "sample_id", min_n = 15) # Default min_n=30
p <- plotAbundanceCurve(a, annotate="depth", silent = T) + 
           facet_wrap(~sample_id)
p
```

# Diversity

The clonal abundance distribution can be characterized using diversity statistics. Diversity scores (D) are calculated using the generalized diversity index (Hill numbers), which covers many different measures of diversity in a single function with a single varying parameter, the diversity order q.

The function alphaDiversity resamples the sequences and calculates diversity scores (D) over a interval of diversity orders (q). The diversity (D) is shown on the y-axis and the x-axis is the parameter q. - q = 0 corresponds to Species Richness - q = 1 corresponds to Shannon Entropy - q = 2 corresponds to Simpson Index

Inspection of this figure is useful to determine whether any difference in diversity between two repertoires depends on the statistic used or if it is a universal property. 

```{r diversity}
# generate the Hill diversity curve
d <- alphaDiversity(db %>% filter(grepl("[hHBbDc]", locus)), group = "sample_id")
p <- plotDiversityCurve(d, silent = T)
p + geom_vline(xintercept = c(0,1,2), color = "grey50", linetype = "dashed") +
    geom_text(data = data.frame(q = c(0,1,2), y = round(max(p$data$d_upper)/2),
              label = c("Richness", "Shannon", "Simpson")),
              aes(x = q, y = y,label = label), size = 3, angle = 90, vjust = -0.4, inherit.aes  =  F, color = "grey50") +
    facet_wrap(~sample_id)
```

# `junction` and `junction_aa` overlap

## Same sequence

Identity of the `junction` and `junction_aa` sequence overlap between `sample_id`
is done using `alakazam::seqEqual`, which allows for ambiguities. 

```{r overlap}
overlap <- plotDbOverlap(db %>% filter(grepl("[hHBbDc]", locus)), 
                         group="sample_id", 
                         features=c("junction_aa","junction"), 
                         heatmap_colors=c("white","orange", "grey80"), 
                         print_zero=FALSE, long_x_angle=90,
                         title=NULL,xlab=NULL, ylab=NULL,
                         plot_order=c("tissue","sample_id"), 
                         silent=T, similarity=c("jaccard","jaccard"),
                         na.rm=FALSE, exact=c(FALSE, FALSE), 
                         geom_text_size=3)
```

```{r overlapplot, fig.width=6, fig.width=0.4*length(unique(db[['sample_id']])), fig.height=0.4*length(unique(db[['sample_id']]))}
overlap$p
```

## TODO: use a threshold

# Save

```{r dbpass}
# pass <- db[['collapse_pass']]

if (!is.null(params$outname)) {
    output_fn <- paste0(params$outname,"_clone-pass.tsv")
} else {
    output_fn <- sub(".tsv$", "_clone-pass.tsv", basename(params$input))
}

if (!is.null(params$log)) {
    log_fn <- paste0(params$log,".txt")
} else {
    log_fn <- sub("_clone-pass.tsv$", "_command_log.txt", basename(output_fn))
}


# db <- data.frame(
#     'id'=c(1,2),
#     'subject_id'=c("A","A")
# )

output_files <- c()
output_sizes <- c()
if (sum(heavy_chains)>0 & nrow(db)>0) {
    
    output_groups <- db %>%
        ungroup() %>%
        select(!!!rlang::syms(params$outputby)) %>%
        distinct() 
    
    if (nrow(output_groups)>0) {
        for (i in 1:nrow(output_groups))  {
            group_db <- right_join(db,
                                   output_groups[i,,drop=F],
                                   by=params$outputby)
            
            group_db_label <- gsub("^id_","",makeLabel(group_db, fields= params$outputby))
            group_fn <- paste0(group_db_label,"_",output_fn)
            output_files <- c(output_files, group_fn)
            output_sizes <- c(output_sizes, nrow(group_db))
            write_rearrangement(group_db, file=group_fn)
        }
    } else {
        write_rearrangement(db, file=output_fn)
    }
}
```


```{r log}
cat("START>ClonePass", file=log_fn, append=F)
cat(paste0("\nFILE> ",basename(params$input)), file=log_fn, append=T)
if (length(output_files==1)) {
    cat(paste0("\nOUTPUT> ",basename(output_fn)), file=log_fn, append=T)
    cat(paste0("\nPASS> ",nrow(db)), file=log_fn, append=T)
} else {
    for (i in 1:length(output_files)) {
        cat(paste0("\nOUTPUT",i,"> ",output_files[i]), file=log_fn, append=T)
        cat(paste0("\nPASS",i,"> ",output_sizes[i]), file=log_fn, append=T)
    }
}
cat(paste0("\nPASS> ",sum(output_sizes)), file=log_fn, append=T)
cat(paste0("\nFAIL> ",input_size-sum(output_sizes)), file=log_fn, append=T)
```


```{r, child=c('versions.Rmd')}
```